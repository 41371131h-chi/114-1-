{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPRmDNHYEK+XQL8Qq/wqcmE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/41371131h-chi/114-1-/blob/main/HW4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NUmNxl8N53uy"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# 0. ç’°å¢ƒè¨­ç½®èˆ‡å‡½å¼åº«å°å…¥\n",
        "# ==============================================================================\n",
        "# --- é‹è¡Œç’°å¢ƒè¨­å®šï¼ˆè«‹åœ¨ Colab Cell ä¸­åŸ·è¡Œï¼‰---\n",
        "!pip -q install gspread gspread_dataframe google-auth google-auth-oauthlib google-auth-httplib2 \\\n",
        "              gradio pandas beautifulsoup4 google-generativeai python-dateutil scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, time, uuid, re, json, datetime\n",
        "from datetime import datetime as dt, timedelta\n",
        "from dateutil.tz import gettz\n",
        "import pandas as pd\n",
        "import gradio as gr\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Google Auth & Sheets\n",
        "from google.colab import auth\n",
        "import gspread\n",
        "from gspread_dataframe import set_with_dataframe, get_as_dataframe\n",
        "from google.auth.transport.requests import Request\n",
        "from google.oauth2 import service_account\n",
        "from google.auth import default"
      ],
      "metadata": {
        "id": "HDOARDS37TLw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TF-IDF (æ–°å¢)\n",
        "try:\n",
        "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "except ImportError:\n",
        "    print(\"âš ï¸ æœªå®‰è£ scikit-learnï¼ŒTF-IDF ç›¸é—œåŠŸèƒ½å¯èƒ½ç„¡æ³•åŸ·è¡Œã€‚è«‹é‹è¡Œï¼š!pip install scikit-learn\")\n",
        "    # å‡è£ TfidfVectorizer å­˜åœ¨ä»¥é¿å…ç¨‹å¼ç¢¼å´©æ½°\n",
        "    class DummyTfidfVectorizer:\n",
        "        def fit_transform(self, X): return None\n",
        "        def get_feature_names_out(self): return []\n",
        "    TfidfVectorizer = DummyTfidfVectorizer"
      ],
      "metadata": {
        "id": "-r3m-ogn7WOf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# èªè­‰èˆ‡ Gemini é…ç½®ï¼ˆè«‹åœ¨ Colab Cell ä¸­åŸ·è¡Œï¼‰\n",
        "auth.authenticate_user()\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "from google.colab import userdata\n",
        "# å¾ Colab Secrets ä¸­ç²å– API é‡‘é‘°\n",
        "try:\n",
        "    api_key = userdata.get('HW3')\n",
        "    # ç¢ºä¿é‡‘é‘°å­˜åœ¨ï¼Œå¦å‰‡ genai.configure æœƒå ±éŒ¯\n",
        "    if not api_key:\n",
        "        raise ValueError(\"Colab Secret 'HW3' is empty or not found.\")\n",
        "\n",
        "    genai.configure(api_key=api_key)\n",
        "    print(\"âœ… Gemini API Key é…ç½®æˆåŠŸã€‚\")\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸ Gemini API Key é…ç½®å¤±æ•—ï¼Œè«‹æª¢æŸ¥ Colab Secrets ä¸­çš„ 'HW3'ï¼š{e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmMyBXit721m",
        "outputId": "965df8a1-19af-4899-9257-dc33aee505f9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Gemini API Key é…ç½®æˆåŠŸã€‚\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 1. å…¨åŸŸè®Šæ•¸èˆ‡ Sheet/DataFrame è¨­ç½®\n",
        "# ==============================================================================\n",
        "\n",
        "# è«‹ç¢ºä¿é€™å€‹ Sheet URL å­˜åœ¨ä¸”æ‚¨æœ‰ç·¨è¼¯æ¬Šé™\n",
        "SHEET_URL = \"https://docs.google.com/spreadsheets/d/1jR3qRQr2ZvWYKNuv8wen_-eTZWdc5a-LLvH7iymn2zw/edit?usp=sharing\"\n",
        "WORKSHEET_NAME = \"å·¥ä½œè¡¨4\" # è®Šæ›´ç‚ºæ›´å°ˆæ³¨æ–¼çˆ¬èŸ²çš„åç¨±\n",
        "TIMEZONE = \"Asia/Taipei\"\n",
        "\n",
        "# Headers for Worksheets\n",
        "CLIPS_HEADER = [\"clip_id\",\"url\",\"selector\",\"text\",\"href\",\"created_at\",\"added_to_task\"]\n",
        "STATS_HEADER = [\"keyword\", \"frequency\", \"score\", \"created_at\"] # TF-IDF çµ±è¨ˆè¡¨é ­"
      ],
      "metadata": {
        "id": "qHaJqYt48AeE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Google Sheet åˆå§‹åŒ–å‡½å¼ ---\n",
        "def ensure_spreadsheet(name):\n",
        "    \"\"\"ç¢ºä¿è©¦ç®—è¡¨å­˜åœ¨ï¼Œè‹¥ç„¡å‰‡å‰µå»ºã€‚\"\"\"\n",
        "    try:\n",
        "        sh = gc.open(name)\n",
        "    except gspread.SpreadsheetNotFound:\n",
        "        sh = gc.create(name)\n",
        "    return sh\n",
        "\n",
        "def ensure_worksheet(sh, title, header):\n",
        "    \"\"\"ç¢ºä¿å·¥ä½œè¡¨å­˜åœ¨ä¸”è¡¨é ­æ­£ç¢ºã€‚\"\"\"\n",
        "    try:\n",
        "        ws = sh.worksheet(title)\n",
        "    except gspread.WorksheetNotFound:\n",
        "        ws = sh.add_worksheet(title=title, rows=\"1000\", cols=str(len(header)+5))\n",
        "        ws.update([header])\n",
        "\n",
        "    # ç¢ºä¿è¡¨é ­æ­£ç¢º\n",
        "    data = ws.get_all_values()\n",
        "    if not data or (data and data[0] != header):\n",
        "        ws.clear()\n",
        "        ws.update([header])\n",
        "    return ws\n",
        "\n",
        "sh = ensure_spreadsheet(WORKSHEET_NAME)\n",
        "ws_clips = ensure_worksheet(sh, \"web_clips\", CLIPS_HEADER)\n",
        "ws_stats = ensure_worksheet(sh, \"tf-idf_stats\", STATS_HEADER)"
      ],
      "metadata": {
        "id": "1KdOsszH8yA9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 2. DataFrame è®€å¯«èˆ‡å¯¦ç”¨å‡½å¼\n",
        "# ==============================================================================\n",
        "\n",
        "def tznow():\n",
        "    return dt.now(gettz(TIMEZONE))"
      ],
      "metadata": {
        "id": "3czLIZDj88Cj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_df(ws, header):\n",
        "    \"\"\"è®€å–å·¥ä½œè¡¨ç‚º DataFrameã€‚\"\"\"\n",
        "    df = get_as_dataframe(ws, evaluate_formulas=True, header=0)\n",
        "    if df is None or df.empty:\n",
        "        return pd.DataFrame(columns=header)\n",
        "    df = df.fillna(\"\")\n",
        "    # ä¿è­‰æ¬„ä½é½Šå…¨\n",
        "    for c in header:\n",
        "        if c not in df.columns:\n",
        "            df[c] = \"\"\n",
        "    # ç§»é™¤ä¸å¿…è¦çš„æ¬„ä½ä¸¦ä¿æŒé †åº\n",
        "    df = df.reindex(columns=header, fill_value=\"\")\n",
        "    return df[header]"
      ],
      "metadata": {
        "id": "czYOp7Km9X1j"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def write_df(ws, df, header):\n",
        "    \"\"\"å°‡ DataFrame å¯«å…¥å·¥ä½œè¡¨ã€‚\"\"\"\n",
        "    if df.empty:\n",
        "        ws.clear()\n",
        "        ws.update([header])\n",
        "        return\n",
        "    # è½‰å­—ä¸²é¿å… gspread å‹åˆ¥å•é¡Œ\n",
        "    df_out = df.copy()\n",
        "    for c in df_out.columns:\n",
        "        df_out[c] = df_out[c].astype(str)\n",
        "    ws.clear()\n",
        "    ws.update([header] + df_out.values.tolist())"
      ],
      "metadata": {
        "id": "yO2HOBeX9GJ8"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def refresh_all():\n",
        "    \"\"\"å¾ Google Sheet é‡æ–°è®€å– web_clips å’Œ tf-idf_statsã€‚\"\"\"\n",
        "    return (\n",
        "        read_df(ws_clips, CLIPS_HEADER).copy(),\n",
        "        read_df(ws_stats, STATS_HEADER).copy()\n",
        "    )\n",
        "\n",
        "clips_df, stats_df = refresh_all()"
      ],
      "metadata": {
        "id": "QaAKs9ON-Cad"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- æ–°å¢ï¼šå¯«å…¥ AI æ‘˜è¦è‡³ Sheet çš„å‡½å¼ ---\n",
        "def write_summary_to_sheet(keywords_str, summary_md):\n",
        "    \"\"\"å°‡ Gemini æ‘˜è¦å¯«å…¥ ai_summary å·¥ä½œè¡¨ï¼Œå°‡æ–°ç´€éŒ„æ”¾åœ¨æœ€å‰é¢ã€‚\"\"\"\n",
        "    global ws_summary\n",
        "\n",
        "    # è®€å–ç¾æœ‰è³‡æ–™\n",
        "    df_existing = read_df(ws_summary, SUMMARY_HEADER)\n",
        "\n",
        "    new_row = pd.DataFrame([{\n",
        "        \"created_at\": tznow().isoformat(),\n",
        "        # ç‚ºäº†ç°¡æ½”ï¼Œå°‡é—œéµè©åˆ—è¡¨è½‰ç‚ºå­—ä¸²å„²å­˜\n",
        "        \"keywords_used\": keywords_str,\n",
        "        \"summary_report\": summary_md\n",
        "    }])\n",
        "\n",
        "    # åˆä½µç¾æœ‰è³‡æ–™å’Œæ–°è³‡æ–™ (å°‡æ–°è³‡æ–™æ”¾åœ¨æœ€å‰é¢)\n",
        "    df_updated = pd.concat([new_row, df_existing], ignore_index=True)\n",
        "\n",
        "    # åªä¿ç•™æ¬„ä½é †åº\n",
        "    df_updated = df_updated[SUMMARY_HEADER]\n",
        "\n",
        "    write_df(ws_summary, df_updated, SUMMARY_HEADER)\n",
        "\n",
        "    return len(df_updated)"
      ],
      "metadata": {
        "id": "e-d2VIQKGTQc"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 3. çˆ¬èŸ²ã€TF-IDF çµ±è¨ˆèˆ‡ Gemini æ‘˜è¦\n",
        "# ==============================================================================\n",
        "\n",
        "def fetch_and_store_clips(url, selector, mode, limit):\n",
        "    \"\"\"åŸ·è¡Œçˆ¬èŸ²ï¼Œä¸¦å°‡çµæœå¯«å…¥ web_clips å·¥ä½œè¡¨ã€‚\"\"\"\n",
        "    global clips_df\n",
        "\n",
        "    if not url or not selector:\n",
        "        return \"âš ï¸ URL æˆ– Selector ä¸å¯ç‚ºç©ºã€‚\", clips_df\n",
        "\n",
        "    try:\n",
        "        resp = requests.get(url, timeout=15, headers={\"User-Agent\":\"Mozilla/5.0\"})\n",
        "        resp.raise_for_status()\n",
        "    except Exception as e:\n",
        "        return f\"âš ï¸ è«‹æ±‚å¤±æ•—ï¼š{e}\", clips_df\n",
        "\n",
        "    soup = BeautifulSoup(resp.text, \"html.parser\")\n",
        "    nodes = soup.select(selector)\n",
        "    rows = []\n",
        "\n",
        "    limit = int(limit) if limit else 20\n",
        "\n",
        "    for i, n in enumerate(nodes[:limit]):\n",
        "        text = n.get_text(strip=True) if mode in (\"text\",\"both\") else \"\"\n",
        "        href = n.get(\"href\") if mode in (\"href\",\"both\") else \"\"\n",
        "\n",
        "        if href and href.startswith(\"/\"):\n",
        "            from urllib.parse import urljoin\n",
        "            href = urljoin(url, href)\n",
        "\n",
        "        rows.append({\n",
        "            \"clip_id\": str(uuid.uuid4())[:8], \"url\": url, \"selector\": selector,\n",
        "            \"text\": text, \"href\": href, \"created_at\": tznow().isoformat(),\n",
        "            \"added_to_task\": \"\" # ä¿ç•™æ­¤æ¬„ä½ä»¥ä¾¿æœªä¾†æ“´å……\n",
        "        })\n",
        "\n",
        "    df = pd.DataFrame(rows, columns=CLIPS_HEADER)\n",
        "\n",
        "    if not df.empty:\n",
        "        # å¯«å…¥æ–°çš„ web_clips è³‡æ–™ (è¦†è“‹)\n",
        "        clips_df = df.copy()\n",
        "        write_df(ws_clips, clips_df, CLIPS_HEADER)\n",
        "    else:\n",
        "        clips_df = pd.DataFrame(columns=CLIPS_HEADER)\n",
        "        write_df(ws_clips, clips_df, CLIPS_HEADER)\n",
        "\n",
        "\n",
        "    return f\"âœ… æˆåŠŸæ“·å– {len(df)} ç­†è³‡æ–™ä¸¦å¯«å…¥ web_clipsã€‚\", clips_df"
      ],
      "metadata": {
        "id": "SWrPKzQM-DDt"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_tfidf_and_store(n_keywords):\n",
        "    \"\"\"å¾ web_clips è®€å–æ–‡æœ¬ï¼Œè¨ˆç®— TF-IDFï¼Œä¸¦å°‡å‰ N ç†±è©å¯«å…¥ tf-idf_statsã€‚\"\"\"\n",
        "    global clips_df, ws_stats, stats_df\n",
        "\n",
        "    texts = clips_df[clips_df['text'].astype(str).str.strip() != '']['text'].tolist()\n",
        "    if not texts:\n",
        "        return \"âš ï¸ çˆ¬èŸ²çµæœç„¡æœ‰æ•ˆæ–‡æœ¬å¯ä¾›çµ±è¨ˆã€‚\", \"\", pd.DataFrame(columns=STATS_HEADER)\n",
        "\n",
        "    n_keywords = int(n_keywords)\n",
        "    # å‡è¨­å¤šæ•¸çˆ¬èŸ²å…§å®¹ç‚ºè‹±æ–‡ï¼Œä½¿ç”¨è‹±æ–‡åœç”¨è©\n",
        "    vectorizer = TfidfVectorizer(stop_words='english', max_features=500, ngram_range=(1, 2))\n",
        "    tfidf_matrix = vectorizer.fit_transform(texts)\n",
        "    feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "    tfidf_scores = tfidf_matrix.max(axis=0).toarray().flatten()\n",
        "\n",
        "    indices = tfidf_scores.argsort()[-n_keywords:][::-1]\n",
        "\n",
        "    stats_rows = []\n",
        "    _now = tznow().isoformat()\n",
        "    for i in indices:\n",
        "        stats_rows.append({\n",
        "            \"keyword\": feature_names[i],\n",
        "            \"frequency\": 0, # Placeholder (TF-IDFä¸ç›´æ¥æ˜¯é »ç‡)\n",
        "            \"score\": round(tfidf_scores[i], 4),\n",
        "            \"created_at\": _now\n",
        "        })\n",
        "\n",
        "    stats_df = pd.DataFrame(stats_rows, columns=STATS_HEADER)\n",
        "\n",
        "    write_df(ws_stats, stats_df, STATS_HEADER)\n",
        "\n",
        "    output_md = \"### ğŸ”¥ é—œéµè© Top {} (TF-IDF Score)\\n\".format(n_keywords)\n",
        "    for _, r in stats_df.iterrows():\n",
        "        output_md += f\"- **{r['keyword']}**ï¼š{r['score']:.4f}\\n\"\n",
        "\n",
        "    return f\"âœ… æˆåŠŸè¨ˆç®— TF-IDF ä¸¦å°‡å‰ {n_keywords} ç†±è©å¯«å…¥ tf-idf_statsã€‚\", output_md, stats_df"
      ],
      "metadata": {
        "id": "ZtaF80c2-I2f"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# *** ä¿®æ­£æ­¤å‡½å¼ä¸­çš„ `if not genai.api_key:` æª¢æŸ¥ ***\n",
        "def generate_summary_and_insight(stats_df):\n",
        "    \"\"\"ä¸²æ¥ Gemini API ç”Ÿæˆ 5 å¥æ´å¯Ÿæ‘˜è¦èˆ‡ 120 å­—çµè«–ã€‚\"\"\"\n",
        "\n",
        "    # --- ä¿®æ­£å¾Œçš„æª¢æŸ¥é‚è¼¯ ---\n",
        "    # æª¢æŸ¥å…¨å±€é…ç½®æ™‚ä½¿ç”¨çš„ api_key è®Šæ•¸æ˜¯å¦å­˜åœ¨æˆ–ç‚ºç©º\n",
        "    global api_key # ç¢ºä¿èƒ½å­˜å–åœ¨é–‹é ­å¾ Colab Secret å–å¾—çš„ api_key è®Šæ•¸\n",
        "    if not api_key:\n",
        "        return \"âš ï¸ Gemini API Key æœªé…ç½®ï¼ˆå…¨åŸŸè®Šæ•¸ `api_key` ç‚ºç©ºï¼‰ï¼Œç„¡æ³•ç”Ÿæˆæ‘˜è¦ã€‚\", \"\"\n",
        "\n",
        "    try:\n",
        "        # å¦‚æœ genai.configure æˆåŠŸï¼Œé€™è£¡å°±å¯ä»¥ç›´æ¥ä½¿ç”¨æ¨¡å‹\n",
        "        model = genai.GenerativeModel('gemini-2.5-pro')\n",
        "    except Exception:\n",
        "        # å¦‚æœæ¨¡å‹åŠ è¼‰å¤±æ•— (ä¾‹å¦‚é…ç½®ä»ç„¶ç„¡æ•ˆ)ï¼Œå‰‡è¿”å›éŒ¯èª¤\n",
        "        return \"âš ï¸ Gemini æ¨¡å‹é…ç½®éŒ¯èª¤æˆ–é‡‘é‘°ç„¡æ•ˆã€‚\", \"\"\n",
        "\n",
        "    if stats_df.empty:\n",
        "        return \"âš ï¸ çµ±è¨ˆæ•¸æ“šç‚ºç©ºï¼Œç„¡æ³•ç”Ÿæˆæ‘˜è¦ã€‚\", \"\"\n",
        "\n",
        "    keywords_str = \"\\n\".join([f\"- {r['keyword']} (Score: {r['score']:.4f})\" for _, r in stats_df.iterrows()])\n",
        "\n",
        "    sys_prompt = (\n",
        "        \"ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„è³‡æ–™åˆ†æå¸«ã€‚è«‹æ ¹æ“šæä¾›çš„é—œéµè©å’Œåˆ†æ•¸ï¼Œç”Ÿæˆä¸€ä»½ç°¡æ½”çš„å ±å‘Šã€‚\\n\"\n",
        "        \"å ±å‘Šå¿…é ˆåŒ…å«å…©å€‹éƒ¨åˆ†ï¼š\\n\"\n",
        "        \"1. **äº”å€‹é—œéµæ´å¯Ÿ (5 Key Insights)**ï¼šä»¥äº”å€‹ç¨ç«‹çš„å¥å­æ¢åˆ—å‡ºä¾†ï¼Œè§£é‡‹é€™äº›é—œéµè©åœ¨ä¸»é¡Œä¸Šçš„æ½›åœ¨æ„ç¾©ã€‚\\n\"\n",
        "        \"2. **çµè«– (Conclusion)**ï¼šä¸€æ®µç´„ 120 å­—çš„ç¸½çµï¼Œæ¦‚æ‹¬é—œéµè©æ‰€é¡¯ç¤ºçš„ä¸»è¦è¶¨å‹¢æˆ–ä¸»é¡Œã€‚\\n\"\n",
        "        \"è«‹ç›´æ¥è¼¸å‡º Markdown æ ¼å¼ã€‚\"\n",
        "    )\n",
        "\n",
        "    user_content = f\"--- é—œéµè©åˆ†æçµæœ ---\\n{keywords_str}\"\n",
        "\n",
        "    try:\n",
        "        resp = model.generate_content(\n",
        "            sys_prompt + \"\\n\\n\" + user_content,\n",
        "            generation_config={\"temperature\": 0.5}\n",
        "        )\n",
        "        return \"âœ… Gemini æ‘˜è¦ç”Ÿæˆå®Œæˆã€‚\", resp.text\n",
        "    except Exception as e:\n",
        "        # æ•æ‰ API è«‹æ±‚æ™‚å¯èƒ½ç™¼ç”Ÿçš„éŒ¯èª¤ (å¦‚ç¶²è·¯å•é¡Œã€API é™åˆ¶ç­‰)\n",
        "        return f\"âš ï¸ Gemini è«‹æ±‚å¤±æ•—ï¼š{e}\", \"\""
      ],
      "metadata": {
        "id": "5GbCBTPY-L3q"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_full_crawler_pipeline(url, selector, mode, limit, n_keywords):\n",
        "    \"\"\"åŸ·è¡Œå®Œæ•´è‡ªå‹•åŒ–æµç¨‹ï¼šçˆ¬èŸ² -> å¯«å…¥ -> TF-IDF -> å¯«å…¥ -> Gemini æ‘˜è¦ -> å¯«å…¥æ‘˜è¦ã€‚\"\"\"\n",
        "\n",
        "    # *** ä¿®æ­£ï¼šå°‡ global è²æ˜ç§»å‹•åˆ°å‡½å¼å…§éƒ¨æœ€é ‚ç«¯ ***\n",
        "    global clips_df, stats_df\n",
        "\n",
        "    # 1. çˆ¬èŸ²èˆ‡å¯«å…¥\n",
        "    msg_crawl, new_clips_df = fetch_and_store_clips(url, selector, mode, limit)\n",
        "\n",
        "    # å¦‚æœçˆ¬èŸ²å¤±æ•—ï¼Œç›´æ¥è¿”å›éŒ¯èª¤\n",
        "    if new_clips_df.empty:\n",
        "        full_report = f\"## ğŸ¤– è‡ªå‹•åŒ–æµç¨‹åŸ·è¡Œå ±å‘Š\\n\\n### æ­¥é©Ÿä¸€ï¼šç¶²é çˆ¬èŸ²èˆ‡è³‡æ–™å¯«å…¥\\n{msg_crawl}\\n\\nâš ï¸ **åš´é‡è­¦å‘Šï¼šçˆ¬èŸ²æœªæ“·å–åˆ°ä»»ä½•æ–‡æœ¬ï¼** TF-IDF èˆ‡ Gemini åˆ†æç„¡æ³•é€²è¡Œã€‚è«‹æª¢æŸ¥æ‚¨çš„ URL å’Œ CSS Selector æ˜¯å¦æ­£ç¢ºã€‚\"\n",
        "        # é€™è£¡ä¸éœ€è¦é‡æ–°è³¦å€¼ï¼Œå› ç‚º clips_df åœ¨ fetch_and_store_clips å…§éƒ¨å·²ç¶“è¢«ä¿®æ”¹ç‚ºç©º DataFrame\n",
        "        return full_report, clips_df, stats_df\n",
        "\n",
        "    # 2. TF-IDF çµ±è¨ˆèˆ‡å¯«å…¥\n",
        "    msg_tfidf, tfidf_md, stats_df_result = calculate_tfidf_and_store(n_keywords)\n",
        "\n",
        "    # 3. Gemini æ‘˜è¦ç”Ÿæˆ\n",
        "    msg_gemini_status, gemini_md = generate_summary_and_insight(stats_df_result)\n",
        "\n",
        "    # --- 4. æ–°å¢ï¼šå°‡æ‘˜è¦å¯«å…¥ ai_summary å·¥ä½œè¡¨ ---\n",
        "    msg_summary_write = \"\"\n",
        "    if not msg_gemini_status.startswith(\"âš ï¸\"):\n",
        "        try:\n",
        "             # æå– TF-IDF é—œéµè©å­—ä¸²\n",
        "             keywords_str = \", \".join(stats_df_result['keyword'].tolist())\n",
        "             write_summary_to_sheet(keywords_str, gemini_md)\n",
        "             msg_summary_write = f\"âœ… æˆåŠŸå°‡ AI æ‘˜è¦å¯«å…¥ ai_summaryã€‚\"\n",
        "        except Exception as e:\n",
        "             msg_summary_write = f\"âš ï¸ å¯«å…¥ AI æ‘˜è¦è‡³ Sheet å¤±æ•—: {e}\"\n",
        "    else:\n",
        "        msg_summary_write = \"âš ï¸ AI æ‘˜è¦ç”Ÿæˆå¤±æ•—ï¼Œæ•…æœªå¯«å…¥ Sheetã€‚\"\n",
        "\n",
        "    # åˆä½µè¼¸å‡º\n",
        "    full_report = (\n",
        "        f\"## ğŸ¤– è‡ªå‹•åŒ–æµç¨‹åŸ·è¡Œå ±å‘Š\\n\\n\"\n",
        "        f\"### æ­¥é©Ÿä¸€ï¼šç¶²é çˆ¬èŸ²èˆ‡è³‡æ–™å¯«å…¥\\n{msg_crawl}\\n\\n\"\n",
        "        f\"### æ­¥é©ŸäºŒï¼šè©é »èˆ‡é—œéµè©çµ±è¨ˆ (TF-IDF)\\n{msg_tfidf}\\n\\n\"\n",
        "        f\"{tfidf_md}\\n\\n\"\n",
        "        f\"### æ­¥é©Ÿä¸‰ï¼šAI æ´å¯Ÿæ‘˜è¦ (Gemini)\\n{msg_gemini_status}\\n\\n\"\n",
        "        f\"### æ­¥é©Ÿå››ï¼šAI æ‘˜è¦å¯«å…¥ Sheet\\n{msg_summary_write}\\n\\n\"\n",
        "        f\"--- AI å ±å‘Š ---\\n\"\n",
        "        f\"{gemini_md}\"\n",
        "    )\n",
        "\n",
        "    # é€™è£¡ä¸éœ€è¦å†æ¬¡å‘¼å« refresh_all()ï¼Œå› ç‚º clips_df å’Œ stats_df åœ¨å‰é¢çš„æ­¥é©Ÿä¸­å·²è¢«å¯«å…¥ä¸¦æ›´æ–°\n",
        "    # ç›´æ¥ä½¿ç”¨å…¨åŸŸè®Šæ•¸ clips_df, stats_df ä½œç‚ºè¿”å›å€¼\n",
        "    return full_report, clips_df, stats_df"
      ],
      "metadata": {
        "id": "tcKHciKv-PEe"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 4. Gradio ä»‹é¢ï¼ˆåƒ…é™çˆ¬èŸ²åˆ†æï¼‰\n",
        "# ==============================================================================\n",
        "\n",
        "def _refresh_dataframes():\n",
        "    \"\"\"åƒ…åˆ·æ–° web_clips å’Œ tf-idf_stats çµ¦ Gradio\"\"\"\n",
        "    global clips_df, stats_df\n",
        "    clips_df, stats_df = refresh_all()\n",
        "    return clips_df, stats_df\n",
        "\n",
        "clips_df, stats_df = refresh_all() # ç¢ºä¿ä»‹é¢åˆå§‹å€¼æœ€æ–°\n",
        "\n",
        "with gr.Blocks(title=\"ç´”çˆ¬èŸ²åˆ†æèˆ‡ AI æ‘˜è¦ï¼ˆGoogle Sheetï¼‹Gradioï¼‰\") as demo:\n",
        "    gr.Markdown(\"# ğŸ•·ï¸ ç¶²é çˆ¬èŸ² â†’ TF-IDF é—œéµè©åˆ†æ â†’ AI æ´å¯Ÿæ‘˜è¦\")\n",
        "    gr.Markdown(\"æ­¤å·¥å…·æœƒè‡ªå‹•åŸ·è¡Œï¼š**çˆ¬èŸ² â†’ å¯«å…¥ Sheet (`web_clips`) â†’ è®€å–æ–‡æœ¬ä¸¦ TF-IDF çµ±è¨ˆ â†’ å¯«å…¥ Sheet (`tf-idf_stats`) â†’ Gemini ç”Ÿæˆæ‘˜è¦**ã€‚\")\n",
        "\n",
        "    with gr.Row():\n",
        "        btn_refresh = gr.Button(\"ğŸ”„ é‡æ–°æ•´ç† Sheet è³‡æ–™ï¼ˆWeb Clips & Statsï¼‰\")\n",
        "\n",
        "    with gr.Tab(\"Crawler Analysis\"):\n",
        "        with gr.Row():\n",
        "            url = gr.Textbox(label=\"ç›®æ¨™ URL\", placeholder=\"https://example.com/news\", value=\"https://www.bbc.com/news\")\n",
        "            selector = gr.Textbox(label=\"CSS Selector\", placeholder=\"h2 a\", value=\"h2 a\")\n",
        "\n",
        "        with gr.Row():\n",
        "            mode = gr.Radio([\"text\",\"href\",\"both\"], value=\"text\", label=\"æ“·å–å…§å®¹\")\n",
        "            limit = gr.Number(value=20, precision=0, label=\"æœ€å¤šæ“·å–å¹¾ç­†\")\n",
        "            n_keywords = gr.Number(value=10, precision=0, label=\"TF-IDF è¼¸å‡ºç†±è©æ•¸ (N)\")\n",
        "\n",
        "        btn_run_crawler = gr.Button(\"ğŸš€ ä¸€éµåŸ·è¡Œçˆ¬èŸ²èˆ‡åˆ†ææµç¨‹\")\n",
        "\n",
        "        out_report = gr.Markdown(\"## å ±å‘Šè¼¸å‡ºå€\")\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                gr.Markdown(\"### åŸå§‹çˆ¬èŸ²çµæœ (web_clips)\")\n",
        "                grid_clips = gr.Dataframe(value=clips_df, label=\"web_clips æœ€æ–°è³‡æ–™\", interactive=False)\n",
        "            with gr.Column():\n",
        "                gr.Markdown(\"### TF-IDF çµ±è¨ˆçµæœ (tf-idf_stats)\")\n",
        "                grid_stats = gr.Dataframe(value=stats_df, label=\"TF-IDF æœ€æ–°çµ±è¨ˆ\", interactive=False)\n",
        "\n",
        "\n",
        "    # === ç¶å®šå‹•ä½œ ===\n",
        "    btn_refresh.click(_refresh_dataframes, outputs=[grid_clips, grid_stats])\n",
        "\n",
        "    btn_run_crawler.click(\n",
        "        run_full_crawler_pipeline,\n",
        "        inputs=[url, selector, mode, limit, n_keywords],\n",
        "        outputs=[out_report, grid_clips, grid_stats]\n",
        "    )"
      ],
      "metadata": {
        "id": "DWG4KjCH-SBe"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demo.launch(debug=True) # åŠ ä¸Š debug=True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eKATNOo-WpQ",
        "outputId": "e1e7bac3-76eb-4161-dab4-dd179ef20237"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://39b6dde4c978d7e8d9.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        }
      ]
    }
  ]
}