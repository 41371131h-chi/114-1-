{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPRmDNHYEK+XQL8Qq/wqcmE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/41371131h-chi/114-1-/blob/main/HW4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NUmNxl8N53uy"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# 0. 環境設置與函式庫導入\n",
        "# ==============================================================================\n",
        "# --- 運行環境設定（請在 Colab Cell 中執行）---\n",
        "!pip -q install gspread gspread_dataframe google-auth google-auth-oauthlib google-auth-httplib2 \\\n",
        "              gradio pandas beautifulsoup4 google-generativeai python-dateutil scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, time, uuid, re, json, datetime\n",
        "from datetime import datetime as dt, timedelta\n",
        "from dateutil.tz import gettz\n",
        "import pandas as pd\n",
        "import gradio as gr\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Google Auth & Sheets\n",
        "from google.colab import auth\n",
        "import gspread\n",
        "from gspread_dataframe import set_with_dataframe, get_as_dataframe\n",
        "from google.auth.transport.requests import Request\n",
        "from google.oauth2 import service_account\n",
        "from google.auth import default"
      ],
      "metadata": {
        "id": "HDOARDS37TLw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TF-IDF (新增)\n",
        "try:\n",
        "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "except ImportError:\n",
        "    print(\"⚠️ 未安裝 scikit-learn，TF-IDF 相關功能可能無法執行。請運行：!pip install scikit-learn\")\n",
        "    # 假裝 TfidfVectorizer 存在以避免程式碼崩潰\n",
        "    class DummyTfidfVectorizer:\n",
        "        def fit_transform(self, X): return None\n",
        "        def get_feature_names_out(self): return []\n",
        "    TfidfVectorizer = DummyTfidfVectorizer"
      ],
      "metadata": {
        "id": "-r3m-ogn7WOf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 認證與 Gemini 配置（請在 Colab Cell 中執行）\n",
        "auth.authenticate_user()\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "from google.colab import userdata\n",
        "# 從 Colab Secrets 中獲取 API 金鑰\n",
        "try:\n",
        "    api_key = userdata.get('HW3')\n",
        "    # 確保金鑰存在，否則 genai.configure 會報錯\n",
        "    if not api_key:\n",
        "        raise ValueError(\"Colab Secret 'HW3' is empty or not found.\")\n",
        "\n",
        "    genai.configure(api_key=api_key)\n",
        "    print(\"✅ Gemini API Key 配置成功。\")\n",
        "except Exception as e:\n",
        "    print(f\"⚠️ Gemini API Key 配置失敗，請檢查 Colab Secrets 中的 'HW3'：{e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmMyBXit721m",
        "outputId": "965df8a1-19af-4899-9257-dc33aee505f9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Gemini API Key 配置成功。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 1. 全域變數與 Sheet/DataFrame 設置\n",
        "# ==============================================================================\n",
        "\n",
        "# 請確保這個 Sheet URL 存在且您有編輯權限\n",
        "SHEET_URL = \"https://docs.google.com/spreadsheets/d/1jR3qRQr2ZvWYKNuv8wen_-eTZWdc5a-LLvH7iymn2zw/edit?usp=sharing\"\n",
        "WORKSHEET_NAME = \"工作表4\" # 變更為更專注於爬蟲的名稱\n",
        "TIMEZONE = \"Asia/Taipei\"\n",
        "\n",
        "# Headers for Worksheets\n",
        "CLIPS_HEADER = [\"clip_id\",\"url\",\"selector\",\"text\",\"href\",\"created_at\",\"added_to_task\"]\n",
        "STATS_HEADER = [\"keyword\", \"frequency\", \"score\", \"created_at\"] # TF-IDF 統計表頭"
      ],
      "metadata": {
        "id": "qHaJqYt48AeE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Google Sheet 初始化函式 ---\n",
        "def ensure_spreadsheet(name):\n",
        "    \"\"\"確保試算表存在，若無則創建。\"\"\"\n",
        "    try:\n",
        "        sh = gc.open(name)\n",
        "    except gspread.SpreadsheetNotFound:\n",
        "        sh = gc.create(name)\n",
        "    return sh\n",
        "\n",
        "def ensure_worksheet(sh, title, header):\n",
        "    \"\"\"確保工作表存在且表頭正確。\"\"\"\n",
        "    try:\n",
        "        ws = sh.worksheet(title)\n",
        "    except gspread.WorksheetNotFound:\n",
        "        ws = sh.add_worksheet(title=title, rows=\"1000\", cols=str(len(header)+5))\n",
        "        ws.update([header])\n",
        "\n",
        "    # 確保表頭正確\n",
        "    data = ws.get_all_values()\n",
        "    if not data or (data and data[0] != header):\n",
        "        ws.clear()\n",
        "        ws.update([header])\n",
        "    return ws\n",
        "\n",
        "sh = ensure_spreadsheet(WORKSHEET_NAME)\n",
        "ws_clips = ensure_worksheet(sh, \"web_clips\", CLIPS_HEADER)\n",
        "ws_stats = ensure_worksheet(sh, \"tf-idf_stats\", STATS_HEADER)"
      ],
      "metadata": {
        "id": "1KdOsszH8yA9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 2. DataFrame 讀寫與實用函式\n",
        "# ==============================================================================\n",
        "\n",
        "def tznow():\n",
        "    return dt.now(gettz(TIMEZONE))"
      ],
      "metadata": {
        "id": "3czLIZDj88Cj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_df(ws, header):\n",
        "    \"\"\"讀取工作表為 DataFrame。\"\"\"\n",
        "    df = get_as_dataframe(ws, evaluate_formulas=True, header=0)\n",
        "    if df is None or df.empty:\n",
        "        return pd.DataFrame(columns=header)\n",
        "    df = df.fillna(\"\")\n",
        "    # 保證欄位齊全\n",
        "    for c in header:\n",
        "        if c not in df.columns:\n",
        "            df[c] = \"\"\n",
        "    # 移除不必要的欄位並保持順序\n",
        "    df = df.reindex(columns=header, fill_value=\"\")\n",
        "    return df[header]"
      ],
      "metadata": {
        "id": "czYOp7Km9X1j"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def write_df(ws, df, header):\n",
        "    \"\"\"將 DataFrame 寫入工作表。\"\"\"\n",
        "    if df.empty:\n",
        "        ws.clear()\n",
        "        ws.update([header])\n",
        "        return\n",
        "    # 轉字串避免 gspread 型別問題\n",
        "    df_out = df.copy()\n",
        "    for c in df_out.columns:\n",
        "        df_out[c] = df_out[c].astype(str)\n",
        "    ws.clear()\n",
        "    ws.update([header] + df_out.values.tolist())"
      ],
      "metadata": {
        "id": "yO2HOBeX9GJ8"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def refresh_all():\n",
        "    \"\"\"從 Google Sheet 重新讀取 web_clips 和 tf-idf_stats。\"\"\"\n",
        "    return (\n",
        "        read_df(ws_clips, CLIPS_HEADER).copy(),\n",
        "        read_df(ws_stats, STATS_HEADER).copy()\n",
        "    )\n",
        "\n",
        "clips_df, stats_df = refresh_all()"
      ],
      "metadata": {
        "id": "QaAKs9ON-Cad"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 新增：寫入 AI 摘要至 Sheet 的函式 ---\n",
        "def write_summary_to_sheet(keywords_str, summary_md):\n",
        "    \"\"\"將 Gemini 摘要寫入 ai_summary 工作表，將新紀錄放在最前面。\"\"\"\n",
        "    global ws_summary\n",
        "\n",
        "    # 讀取現有資料\n",
        "    df_existing = read_df(ws_summary, SUMMARY_HEADER)\n",
        "\n",
        "    new_row = pd.DataFrame([{\n",
        "        \"created_at\": tznow().isoformat(),\n",
        "        # 為了簡潔，將關鍵詞列表轉為字串儲存\n",
        "        \"keywords_used\": keywords_str,\n",
        "        \"summary_report\": summary_md\n",
        "    }])\n",
        "\n",
        "    # 合併現有資料和新資料 (將新資料放在最前面)\n",
        "    df_updated = pd.concat([new_row, df_existing], ignore_index=True)\n",
        "\n",
        "    # 只保留欄位順序\n",
        "    df_updated = df_updated[SUMMARY_HEADER]\n",
        "\n",
        "    write_df(ws_summary, df_updated, SUMMARY_HEADER)\n",
        "\n",
        "    return len(df_updated)"
      ],
      "metadata": {
        "id": "e-d2VIQKGTQc"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 3. 爬蟲、TF-IDF 統計與 Gemini 摘要\n",
        "# ==============================================================================\n",
        "\n",
        "def fetch_and_store_clips(url, selector, mode, limit):\n",
        "    \"\"\"執行爬蟲，並將結果寫入 web_clips 工作表。\"\"\"\n",
        "    global clips_df\n",
        "\n",
        "    if not url or not selector:\n",
        "        return \"⚠️ URL 或 Selector 不可為空。\", clips_df\n",
        "\n",
        "    try:\n",
        "        resp = requests.get(url, timeout=15, headers={\"User-Agent\":\"Mozilla/5.0\"})\n",
        "        resp.raise_for_status()\n",
        "    except Exception as e:\n",
        "        return f\"⚠️ 請求失敗：{e}\", clips_df\n",
        "\n",
        "    soup = BeautifulSoup(resp.text, \"html.parser\")\n",
        "    nodes = soup.select(selector)\n",
        "    rows = []\n",
        "\n",
        "    limit = int(limit) if limit else 20\n",
        "\n",
        "    for i, n in enumerate(nodes[:limit]):\n",
        "        text = n.get_text(strip=True) if mode in (\"text\",\"both\") else \"\"\n",
        "        href = n.get(\"href\") if mode in (\"href\",\"both\") else \"\"\n",
        "\n",
        "        if href and href.startswith(\"/\"):\n",
        "            from urllib.parse import urljoin\n",
        "            href = urljoin(url, href)\n",
        "\n",
        "        rows.append({\n",
        "            \"clip_id\": str(uuid.uuid4())[:8], \"url\": url, \"selector\": selector,\n",
        "            \"text\": text, \"href\": href, \"created_at\": tznow().isoformat(),\n",
        "            \"added_to_task\": \"\" # 保留此欄位以便未來擴充\n",
        "        })\n",
        "\n",
        "    df = pd.DataFrame(rows, columns=CLIPS_HEADER)\n",
        "\n",
        "    if not df.empty:\n",
        "        # 寫入新的 web_clips 資料 (覆蓋)\n",
        "        clips_df = df.copy()\n",
        "        write_df(ws_clips, clips_df, CLIPS_HEADER)\n",
        "    else:\n",
        "        clips_df = pd.DataFrame(columns=CLIPS_HEADER)\n",
        "        write_df(ws_clips, clips_df, CLIPS_HEADER)\n",
        "\n",
        "\n",
        "    return f\"✅ 成功擷取 {len(df)} 筆資料並寫入 web_clips。\", clips_df"
      ],
      "metadata": {
        "id": "SWrPKzQM-DDt"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_tfidf_and_store(n_keywords):\n",
        "    \"\"\"從 web_clips 讀取文本，計算 TF-IDF，並將前 N 熱詞寫入 tf-idf_stats。\"\"\"\n",
        "    global clips_df, ws_stats, stats_df\n",
        "\n",
        "    texts = clips_df[clips_df['text'].astype(str).str.strip() != '']['text'].tolist()\n",
        "    if not texts:\n",
        "        return \"⚠️ 爬蟲結果無有效文本可供統計。\", \"\", pd.DataFrame(columns=STATS_HEADER)\n",
        "\n",
        "    n_keywords = int(n_keywords)\n",
        "    # 假設多數爬蟲內容為英文，使用英文停用詞\n",
        "    vectorizer = TfidfVectorizer(stop_words='english', max_features=500, ngram_range=(1, 2))\n",
        "    tfidf_matrix = vectorizer.fit_transform(texts)\n",
        "    feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "    tfidf_scores = tfidf_matrix.max(axis=0).toarray().flatten()\n",
        "\n",
        "    indices = tfidf_scores.argsort()[-n_keywords:][::-1]\n",
        "\n",
        "    stats_rows = []\n",
        "    _now = tznow().isoformat()\n",
        "    for i in indices:\n",
        "        stats_rows.append({\n",
        "            \"keyword\": feature_names[i],\n",
        "            \"frequency\": 0, # Placeholder (TF-IDF不直接是頻率)\n",
        "            \"score\": round(tfidf_scores[i], 4),\n",
        "            \"created_at\": _now\n",
        "        })\n",
        "\n",
        "    stats_df = pd.DataFrame(stats_rows, columns=STATS_HEADER)\n",
        "\n",
        "    write_df(ws_stats, stats_df, STATS_HEADER)\n",
        "\n",
        "    output_md = \"### 🔥 關鍵詞 Top {} (TF-IDF Score)\\n\".format(n_keywords)\n",
        "    for _, r in stats_df.iterrows():\n",
        "        output_md += f\"- **{r['keyword']}**：{r['score']:.4f}\\n\"\n",
        "\n",
        "    return f\"✅ 成功計算 TF-IDF 並將前 {n_keywords} 熱詞寫入 tf-idf_stats。\", output_md, stats_df"
      ],
      "metadata": {
        "id": "ZtaF80c2-I2f"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# *** 修正此函式中的 `if not genai.api_key:` 檢查 ***\n",
        "def generate_summary_and_insight(stats_df):\n",
        "    \"\"\"串接 Gemini API 生成 5 句洞察摘要與 120 字結論。\"\"\"\n",
        "\n",
        "    # --- 修正後的檢查邏輯 ---\n",
        "    # 檢查全局配置時使用的 api_key 變數是否存在或為空\n",
        "    global api_key # 確保能存取在開頭從 Colab Secret 取得的 api_key 變數\n",
        "    if not api_key:\n",
        "        return \"⚠️ Gemini API Key 未配置（全域變數 `api_key` 為空），無法生成摘要。\", \"\"\n",
        "\n",
        "    try:\n",
        "        # 如果 genai.configure 成功，這裡就可以直接使用模型\n",
        "        model = genai.GenerativeModel('gemini-2.5-pro')\n",
        "    except Exception:\n",
        "        # 如果模型加載失敗 (例如配置仍然無效)，則返回錯誤\n",
        "        return \"⚠️ Gemini 模型配置錯誤或金鑰無效。\", \"\"\n",
        "\n",
        "    if stats_df.empty:\n",
        "        return \"⚠️ 統計數據為空，無法生成摘要。\", \"\"\n",
        "\n",
        "    keywords_str = \"\\n\".join([f\"- {r['keyword']} (Score: {r['score']:.4f})\" for _, r in stats_df.iterrows()])\n",
        "\n",
        "    sys_prompt = (\n",
        "        \"你是一位專業的資料分析師。請根據提供的關鍵詞和分數，生成一份簡潔的報告。\\n\"\n",
        "        \"報告必須包含兩個部分：\\n\"\n",
        "        \"1. **五個關鍵洞察 (5 Key Insights)**：以五個獨立的句子條列出來，解釋這些關鍵詞在主題上的潛在意義。\\n\"\n",
        "        \"2. **結論 (Conclusion)**：一段約 120 字的總結，概括關鍵詞所顯示的主要趨勢或主題。\\n\"\n",
        "        \"請直接輸出 Markdown 格式。\"\n",
        "    )\n",
        "\n",
        "    user_content = f\"--- 關鍵詞分析結果 ---\\n{keywords_str}\"\n",
        "\n",
        "    try:\n",
        "        resp = model.generate_content(\n",
        "            sys_prompt + \"\\n\\n\" + user_content,\n",
        "            generation_config={\"temperature\": 0.5}\n",
        "        )\n",
        "        return \"✅ Gemini 摘要生成完成。\", resp.text\n",
        "    except Exception as e:\n",
        "        # 捕捉 API 請求時可能發生的錯誤 (如網路問題、API 限制等)\n",
        "        return f\"⚠️ Gemini 請求失敗：{e}\", \"\""
      ],
      "metadata": {
        "id": "5GbCBTPY-L3q"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_full_crawler_pipeline(url, selector, mode, limit, n_keywords):\n",
        "    \"\"\"執行完整自動化流程：爬蟲 -> 寫入 -> TF-IDF -> 寫入 -> Gemini 摘要 -> 寫入摘要。\"\"\"\n",
        "\n",
        "    # *** 修正：將 global 聲明移動到函式內部最頂端 ***\n",
        "    global clips_df, stats_df\n",
        "\n",
        "    # 1. 爬蟲與寫入\n",
        "    msg_crawl, new_clips_df = fetch_and_store_clips(url, selector, mode, limit)\n",
        "\n",
        "    # 如果爬蟲失敗，直接返回錯誤\n",
        "    if new_clips_df.empty:\n",
        "        full_report = f\"## 🤖 自動化流程執行報告\\n\\n### 步驟一：網頁爬蟲與資料寫入\\n{msg_crawl}\\n\\n⚠️ **嚴重警告：爬蟲未擷取到任何文本！** TF-IDF 與 Gemini 分析無法進行。請檢查您的 URL 和 CSS Selector 是否正確。\"\n",
        "        # 這裡不需要重新賦值，因為 clips_df 在 fetch_and_store_clips 內部已經被修改為空 DataFrame\n",
        "        return full_report, clips_df, stats_df\n",
        "\n",
        "    # 2. TF-IDF 統計與寫入\n",
        "    msg_tfidf, tfidf_md, stats_df_result = calculate_tfidf_and_store(n_keywords)\n",
        "\n",
        "    # 3. Gemini 摘要生成\n",
        "    msg_gemini_status, gemini_md = generate_summary_and_insight(stats_df_result)\n",
        "\n",
        "    # --- 4. 新增：將摘要寫入 ai_summary 工作表 ---\n",
        "    msg_summary_write = \"\"\n",
        "    if not msg_gemini_status.startswith(\"⚠️\"):\n",
        "        try:\n",
        "             # 提取 TF-IDF 關鍵詞字串\n",
        "             keywords_str = \", \".join(stats_df_result['keyword'].tolist())\n",
        "             write_summary_to_sheet(keywords_str, gemini_md)\n",
        "             msg_summary_write = f\"✅ 成功將 AI 摘要寫入 ai_summary。\"\n",
        "        except Exception as e:\n",
        "             msg_summary_write = f\"⚠️ 寫入 AI 摘要至 Sheet 失敗: {e}\"\n",
        "    else:\n",
        "        msg_summary_write = \"⚠️ AI 摘要生成失敗，故未寫入 Sheet。\"\n",
        "\n",
        "    # 合併輸出\n",
        "    full_report = (\n",
        "        f\"## 🤖 自動化流程執行報告\\n\\n\"\n",
        "        f\"### 步驟一：網頁爬蟲與資料寫入\\n{msg_crawl}\\n\\n\"\n",
        "        f\"### 步驟二：詞頻與關鍵詞統計 (TF-IDF)\\n{msg_tfidf}\\n\\n\"\n",
        "        f\"{tfidf_md}\\n\\n\"\n",
        "        f\"### 步驟三：AI 洞察摘要 (Gemini)\\n{msg_gemini_status}\\n\\n\"\n",
        "        f\"### 步驟四：AI 摘要寫入 Sheet\\n{msg_summary_write}\\n\\n\"\n",
        "        f\"--- AI 報告 ---\\n\"\n",
        "        f\"{gemini_md}\"\n",
        "    )\n",
        "\n",
        "    # 這裡不需要再次呼叫 refresh_all()，因為 clips_df 和 stats_df 在前面的步驟中已被寫入並更新\n",
        "    # 直接使用全域變數 clips_df, stats_df 作為返回值\n",
        "    return full_report, clips_df, stats_df"
      ],
      "metadata": {
        "id": "tcKHciKv-PEe"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 4. Gradio 介面（僅限爬蟲分析）\n",
        "# ==============================================================================\n",
        "\n",
        "def _refresh_dataframes():\n",
        "    \"\"\"僅刷新 web_clips 和 tf-idf_stats 給 Gradio\"\"\"\n",
        "    global clips_df, stats_df\n",
        "    clips_df, stats_df = refresh_all()\n",
        "    return clips_df, stats_df\n",
        "\n",
        "clips_df, stats_df = refresh_all() # 確保介面初始值最新\n",
        "\n",
        "with gr.Blocks(title=\"純爬蟲分析與 AI 摘要（Google Sheet＋Gradio）\") as demo:\n",
        "    gr.Markdown(\"# 🕷️ 網頁爬蟲 → TF-IDF 關鍵詞分析 → AI 洞察摘要\")\n",
        "    gr.Markdown(\"此工具會自動執行：**爬蟲 → 寫入 Sheet (`web_clips`) → 讀取文本並 TF-IDF 統計 → 寫入 Sheet (`tf-idf_stats`) → Gemini 生成摘要**。\")\n",
        "\n",
        "    with gr.Row():\n",
        "        btn_refresh = gr.Button(\"🔄 重新整理 Sheet 資料（Web Clips & Stats）\")\n",
        "\n",
        "    with gr.Tab(\"Crawler Analysis\"):\n",
        "        with gr.Row():\n",
        "            url = gr.Textbox(label=\"目標 URL\", placeholder=\"https://example.com/news\", value=\"https://www.bbc.com/news\")\n",
        "            selector = gr.Textbox(label=\"CSS Selector\", placeholder=\"h2 a\", value=\"h2 a\")\n",
        "\n",
        "        with gr.Row():\n",
        "            mode = gr.Radio([\"text\",\"href\",\"both\"], value=\"text\", label=\"擷取內容\")\n",
        "            limit = gr.Number(value=20, precision=0, label=\"最多擷取幾筆\")\n",
        "            n_keywords = gr.Number(value=10, precision=0, label=\"TF-IDF 輸出熱詞數 (N)\")\n",
        "\n",
        "        btn_run_crawler = gr.Button(\"🚀 一鍵執行爬蟲與分析流程\")\n",
        "\n",
        "        out_report = gr.Markdown(\"## 報告輸出區\")\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                gr.Markdown(\"### 原始爬蟲結果 (web_clips)\")\n",
        "                grid_clips = gr.Dataframe(value=clips_df, label=\"web_clips 最新資料\", interactive=False)\n",
        "            with gr.Column():\n",
        "                gr.Markdown(\"### TF-IDF 統計結果 (tf-idf_stats)\")\n",
        "                grid_stats = gr.Dataframe(value=stats_df, label=\"TF-IDF 最新統計\", interactive=False)\n",
        "\n",
        "\n",
        "    # === 綁定動作 ===\n",
        "    btn_refresh.click(_refresh_dataframes, outputs=[grid_clips, grid_stats])\n",
        "\n",
        "    btn_run_crawler.click(\n",
        "        run_full_crawler_pipeline,\n",
        "        inputs=[url, selector, mode, limit, n_keywords],\n",
        "        outputs=[out_report, grid_clips, grid_stats]\n",
        "    )"
      ],
      "metadata": {
        "id": "DWG4KjCH-SBe"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demo.launch(debug=True) # 加上 debug=True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eKATNOo-WpQ",
        "outputId": "e1e7bac3-76eb-4161-dab4-dd179ef20237"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://39b6dde4c978d7e8d9.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        }
      ]
    }
  ]
}